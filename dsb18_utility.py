{"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nfrom PIL import Image\nimport cv2\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset\nfrom torchmetrics import IoU\n\nfrom skimage.morphology import label\nfrom skimage.transform import resize\nfrom scipy.ndimage import binary_fill_holes\n\n# display a part of the directory tree \n# modified on source: \"https://realpython.com/python-pathlib/#display-a-directory-tree\")\ndef dir_tree(directory, stopped=50):\n    print(f'+ {directory}')\n    for count, path in enumerate(sorted(directory.rglob('*'))):\n        depth = len(path.relative_to(directory).parts)\n        spacer = '    ' * depth\n        print(f'{spacer}+ {path.name}')\n        if count == stopped:\n            break\n            \n# concatenate all individual masks of one Image ID to one combined mask\ndef combine_masks(folder, img_id, height, width):\n    combined_mask = np.zeros((height,width))\n    mask_folder = os.path.join(folder, img_id, \"masks\")\n    masks = os.listdir(mask_folder)\n    for mask in masks:\n        mask_img = Image.open(os.path.join(mask_folder,mask))\n        mask_img = mask_img.resize((height,width), Image.NEAREST)\n        mask_array = np.array(mask_img) / 255\n        combined_mask = np.maximum(combined_mask, mask_array)\n    return combined_mask\n\n# TO BE DONE: does not work for inputs (3, 256, 256)\ndef batch_to_image(batch, index=0):\n    \"\"\"\n    Displays one item of a batch (inputs, targets or outputs) as an image\n    \"\"\"\n    plt.imshow(batch[index].cpu().detach().numpy().squeeze());\n\n\nclass NucleiDataset(Dataset):\n    def __init__(self, rootdir, label_df, input_albums=None, mask_albums=None):\n        self.rootdir = rootdir\n        self.label_df = label_df \n        self.input_albums = input_albums\n        self.mask_albums = mask_albums\n        self.img_ids = list(set(np.asarray(self.label_df.iloc[:,0])))\n    \n    def __getitem__(self, idx):\n        img_id = self.img_ids[idx]\n        img = Image.open(os.path.join(self.rootdir, img_id, \"images\", img_id + \".png\"))\n        img = np.array(img)[...,:3] # removing the fourth transparency layer\n        if self.input_albums is not None:\n            img = self.input_albums(image=img)[\"image\"]\n        \n        mask = combine_masks(self.rootdir, img_id, 256, 256)\n        if self.mask_albums is not None:\n            mask = self.mask_albums(image=mask)[\"image\"]\n        return (img, mask, img_id)\n    \n    def __len__(self):\n        return len(self.img_ids)\n    \nclass NucleiTestDataset(Dataset):\n    def __init__(self, rootdir, img_ids, input_albums=None):\n        self.rootdir = rootdir\n        self.img_ids = img_ids\n        self.input_albums = input_albums\n    \n    def __getitem__(self, idx):\n        img_id = self.img_ids[idx]\n        #img = Image.open(os.path.join(self.rootdir, img_id, \"images\", img_id + \".png\"))\n        img = cv2.imread(os.path.join(self.rootdir, img_id, \"images\", img_id + \".png\"))[:,:,:3]\n        #img = np.array(img, dtype=np.float32)\n        height, width, _ = img.shape\n        # if len(img.size) == 2:\n            # helps to handle specific \n        #    img = np.zeros((1024, 1360, 4))'\n        #img = img[...,:3] # removing the fourth transparency layer\n        if self.input_albums is not None:\n            img = self.input_albums(image=img)[\"image\"]\n        return (img, img_id, height, width)\n    \n    def __len__(self):\n        return len(self.img_ids)\n    \n# to be done: rename image_types\ndef check_dataloaders(dataloaders, index=0):\n    dataiter = iter(dataloaders)\n    img_types = {}\n    img_types[\"Image\"], img_types[\"Mask\"], img_id = dataiter.next()\n    \n    print(\"Image ID:\", img_id[index])\n    fig, axs = plt.subplots(1, 2, figsize=(10,10))\n    for position, task in enumerate([\"Image\", \"Mask\"]):\n        # get first image in the batch\n        im = img_types[task].numpy()\n        im = im[index,:,:,:]\n\n        # permute to [Channel x Height x Width]\n        im = im.transpose((1,2,0))\n        \n        axs.ravel()[position].imshow(im)\n        axs.ravel()[position].set_title(task)\n    plt.show()\n    \n\nclass SimpleNet(nn.Module):\n    def __init__(self):\n        super(SimpleNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n        self.conv2 = nn.Conv2d(32, 128, 3, padding=1)\n        self.conv3 = nn.Conv2d(128, 256, 3, padding=1)\n        self.conv4 = nn.Conv2d(256, 512, 3, padding=1)\n        self.conv5 = nn.Conv2d(512, 1, 1)\n        \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        x = F.relu(self.conv4(x))\n        x = self.conv5(x)\n        return x\n\n# source: https://www.youtube.com/watch?v=IHq1t7NxS8k; Aladdin Persson\nclass DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(DoubleConv, self).__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n    \n    def forward(self, x):\n        return self.conv(x)\n    \nclass UNET(nn.Module):\n    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256,512]):\n        super(UNET, self).__init__()\n        self.ups = nn.ModuleList()\n        self.downs = nn.ModuleList()\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        \n        # down part\n        for feature in features:\n            self.downs.append(DoubleConv(in_channels, feature))\n            in_channels = feature\n            \n        # up part\n        for feature in reversed(features):\n            self.ups.append(\n                nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2)\n            )\n            self.ups.append(DoubleConv(feature*2, feature))\n        \n        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n        \n    def forward(self, x):\n        skip_connections = []\n        for down in self.downs:\n            x = down(x)\n            skip_connections.append(x)\n            x = self.pool(x)\n        \n        x = self.bottleneck(x)\n        # reverses the list; highest to lowest resolution --> lowest to highest resolution\n        skip_connections = skip_connections[::-1]\n        \n        for idx in range(0, len(self.ups), 2):\n            x = self.ups[idx](x)\n            skip_connection = skip_connections[idx//2]\n            concat_skip = torch.cat((skip_connection, x), dim=1)\n            x = self.ups[idx+1](concat_skip)\n            \n        return self.final_conv(x)\n    \n    \nclass Engine():\n    def __init__(self, model, optimizer, device):\n        \"\"\"\n        Args:\n            model (torch.nn.module): Prepared model for task\n            optimizer (torch.optim): Optimizer for task\n            device (string): Device, where the model is stored\n        \"\"\"\n        self.model = model\n        self.optimizer = optimizer\n        self.device = device\n    \n    @staticmethod\n    def loss_fn(outputs, targets):\n        return nn.BCEWithLogitsLoss()(outputs, targets)\n    \n    def train(self, dataloader):\n        self.model.train()\n        iou = IoU(num_classes=2)\n        iou_value = 0.0\n        running_loss = 0.0\n        for inputs, targets, _ in dataloader:\n            self.optimizer.zero_grad()\n            inputs = inputs.to(self.device, dtype=torch.float)\n            targets = targets.to(self.device, dtype=torch.uint8) # maybe change uint8 to float32\n            outputs = self.model(inputs)\n            loss = self.loss_fn(outputs, targets.type_as(outputs))\n            loss.backward()\n            self.optimizer.step()\n            running_loss += loss.item()\n            iou_value += iou(nn.Sigmoid()(outputs).cpu(), targets.cpu())\n        return running_loss / len(dataloader), iou_value / len(dataloader)\n    \n    def evaluate(self, dataloader):\n        self.model.eval()\n        iou = IoU(num_classes=2)\n        iou_value = 0.0\n        running_loss = 0.0\n        for inputs, targets, _ in dataloader:\n            inputs = inputs.to(self.device, dtype=torch.float)\n            targets = targets.to(self.device, dtype=torch.uint8) # maybe change uint8 to float32\n            outputs = self.model(inputs)\n            loss = self.loss_fn(outputs, targets.type_as(outputs))\n            running_loss += loss.item()\n            iou_value += iou(nn.Sigmoid()(outputs).cpu(), targets.cpu())\n        return running_loss / len(dataloader), iou_value / len(dataloader)\n    \n    def predict(self, dataloader):\n        self.model.eval()\n        inference_df = pd.DataFrame()\n        for inputs, img_id, height, width in dataloader:\n            inputs = inputs.to(self.device, dtype=torch.float)\n            outputs = self.model(inputs)\n            outputs_np = outputs.cpu().detach().numpy()\n            preds = []\n            for index in range(outputs_np.shape[0]):\n                img = outputs_np[index].squeeze()\n                img = resize(img, (height[index], width[index]), mode='constant')\n                clean_img = binary_fill_holes(img>0.5)\n                preds.append(list(prob_to_rles(clean_img)))\n            iter_df = pd.DataFrame({\"ImageId\": list(img_id), \"EncodedPixels\": preds})\n            iter_df = iter_df.explode(\"EncodedPixels\")\n            # convert from [1291, 1, 1365, 3] to [1291 1 1365 3]\n            #iter_df.EncodedPixels = iter_df.EncodedPixels.apply(str)\n            #iter_df.EncodedPixels = iter_df.EncodedPixels.apply(lambda row: \" \".join([str(x) for x in row]))\n            inference_df = inference_df.append(iter_df, ignore_index=True)\n        return inference_df\n    \n    def predict_print(self, dataloader):\n        self.model.eval()\n        inference_df = pd.DataFrame()\n        pred_imgs = []\n        #input_imgs = []\n        pred_ids = []\n        for inputs, img_id, height, width in dataloader:\n            inputs = inputs.to(self.device, dtype=torch.float)\n            with torch.no_grad():\n                outputs = self.model(inputs)\n                outputs_np = outputs.cpu().detach().numpy()\n                preds = []\n                for index in range(outputs_np.shape[0]):\n                    img = outputs_np[index].squeeze()\n                    img = resize(img, (height[index], width[index]), mode='constant')\n                    clean_img = binary_fill_holes(img>0.5)\n                    if index==0:\n                        #input_imgs.append(inputs[index].cpu().detach().numpy())\n                        pred_ids.append(img_id[index])\n                        pred_imgs.append(clean_img)\n                    preds.append(list(prob_to_rles(clean_img)))\n            iter_df = pd.DataFrame({\"ImageId\": list(img_id), \"EncodedPixels\": preds})\n            iter_df = iter_df.explode(\"EncodedPixels\")\n            # convert from [1291, 1, 1365, 3] to [1291 1 1365 3]\n            #iter_df.EncodedPixels = iter_df.EncodedPixels.apply(str)\n            #iter_df.EncodedPixels = iter_df.EncodedPixels.apply(lambda row: \" \".join([str(x) for x in row]))\n            inference_df = inference_df.append(iter_df, ignore_index=True)\n        return inference_df, pred_ids, pred_imgs\n    \n    def predict_all_images(self, dataloader):\n        self.model.eval()\n        pred_imgs = []\n        pred_ids = []\n        for inputs, img_id, height, width in dataloader:\n            pred_ids = pred_ids + list(img_id)\n            inputs = inputs.to(self.device, dtype=torch.float)\n            with torch.no_grad():\n                outputs = self.model(inputs)\n                outputs_np = outputs.cpu().detach().numpy()\n                for index in range(outputs_np.shape[0]):\n                    img = outputs_np[index].squeeze()\n                    img = resize(img, (height[index], width[index]), mode='constant')\n                    clean_img = binary_fill_holes(img>0.5)\n                    pred_imgs.append(clean_img)\n        return pred_ids, pred_imgs\n            \ndef get_one_batch(dataloader):\n    dataiter = iter(dataloader)\n    img_types = {}\n    img_types[\"Image\"], img_types[\"Mask\"], img_id = dataiter.next()\n    return img_types, img_id\n\n# prints images, masks and predictions\ndef check_output(img_types, img_id, model, device, index=0):\n    # get predictions through network\n    model.eval()\n    inputs = img_types[\"Image\"].to(device, dtype=torch.float)\n    outputs = model(inputs)\n    img_types[\"Prediction\"] = (outputs>0.5).cpu()\n\n    print(\"Image ID:\", img_id[index])\n    fig, axs = plt.subplots(1, 3, figsize=(10,10))\n    for position, task in enumerate([\"Image\", \"Mask\", \"Prediction\"]):\n        # get first image in the batch\n        im = img_types[task].numpy()\n        im = im[index,:,:,:]\n\n        # permute to [Channel x Height x Width]\n        im = im.transpose((1,2,0))\n\n        axs.ravel()[position].imshow(im)\n        axs.ravel()[position].set_title(task)\n    plt.show()\n  \n\n# Run-length encoding from https://www.kaggle.com/rakhlin/fast-run-length-encoding-python\ndef rle_encoding(x):\n    dots = np.where(x.T.flatten() == 1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return run_lengths\n\ndef prob_to_rles(x, cutoff=0.5):\n    lab_img = label(x > cutoff)\n    for i in range(1, lab_img.max() + 1):\n        yield rle_encoding(lab_img == i)\n    \n    \n    \n\n    \n\n","metadata":{"collapsed":false,"_kg_hide-input":false,"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]}]}